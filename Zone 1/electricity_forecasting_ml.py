# -*- coding: utf-8 -*-
"""Electricity Forecasting - ML.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/118JfByaaLmVrr7naWuq3HkEKRNVB1Idb
"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns

from sklearn.preprocessing import MinMaxScaler, StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression, SGDRegressor, ridge_regression, Lasso, Ridge
from sklearn.svm import SVR
from sklearn.compose import ColumnTransformer
from sklearn.metrics import r2_score

import pickle

# Install dependencies as needed:
# pip install kagglehub[pandas-datasets]
import kagglehub
from kagglehub import KaggleDatasetAdapter

# Set the path to the file you'd like to load
file_path = "powerconsumption.csv"

# Load the latest version
data_set = kagglehub.load_dataset(
  KaggleDatasetAdapter.PANDAS,
  "fedesoriano/electric-power-consumption",
  file_path,
  # Provide any additional arguments like
  # sql_query or pandas_kwargs. See the
  # documenation for more information:
  # https://github.com/Kaggle/kagglehub/blob/main/README.md#kaggledatasetadapterpandas
)

print("First 5 records:", data_set.head())

data_set['Datetime'] = pd.to_datetime(data_set['Datetime'], infer_datetime_format=True)

data_set['Day'] = data_set['Datetime'].dt.day
data_set['Month'] = data_set['Datetime'].dt.month
data_set['Year'] = data_set['Datetime'].dt.year

plt.figure(figsize=(10, 8))
sns.heatmap(data_set.corr(), cmap='RdBu', annot=True, fmt=".2f")
plt.show()

features = data_set.columns.to_list()
targets = [
    'PowerConsumption_Zone1',
    'PowerConsumption_Zone2',
    'PowerConsumption_Zone3'
    ]

for i in targets:
  features.remove(i)
targets = ['PowerConsumption_Zone1']
features.remove('Datetime')

X = data_set[features]
y = data_set[targets]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.25)

scaler = StandardScaler()

X_train_scaled = scaler.fit_transform(X_train)

X_validation_scaled = scaler.transform(X_validation)



regressor = LinearRegression()
lasso = Lasso()
ridge = Ridge()

regressor.fit(X_train_scaled, y_train)

print(r2_score(y_validation, regressor.predict(X_validation_scaled)))
print(r2_score(y_train, regressor.predict(X_train_scaled)))

print(regressor.get_params())
print(lasso.get_params())
print(ridge.get_params())

reg_params = {'copy_X': [True], 'fit_intercept': [True], 'n_jobs': [None], 'positive': [True, False]}


lasso_params = {'alpha': [0.001, 0.01, 0.1, 0.5, 1.0, 5, 10], 'copy_X': [True], 'fit_intercept': [True], 'max_iter': [100, 500, 1000], 'positive': [False], 'precompute': [False], 'random_state': [None], 'selection': ['cyclic'], 'tol': [0.0001], 'warm_start': [False]}


ridge_params = {'alpha': [0.001, 0.01, 0.1, 0.5, 1.0], 'copy_X': [True], 'fit_intercept': [True], 'max_iter': [None], 'positive': [False], 'random_state': [None], 'solver': ['auto'], 'tol': [0.0001]}

grid_search_reg = GridSearchCV(regressor, reg_params, cv=5, scoring='neg_mean_squared_error')
grid_search_reg.fit(X_train_scaled, y_train)

grid_search_reg.best_score_

grid_search_lasso = GridSearchCV(lasso, lasso_params, cv=5, scoring='neg_mean_squared_error')
grid_search_lasso.fit(X_train_scaled, y_train)

grid_search_lasso.best_score_

grid_search_lasso.best_params_

grid_search_ridge = GridSearchCV(ridge, ridge_params, cv=5)
grid_search_ridge.fit(X_train_scaled, y_train)

grid_search_ridge.best_score_

grid_search_ridge.best_params_











regressor = LinearRegression(n_jobs=1, fit_intercept=True)

regressor.fit(X_train_scaled, y_train)

y_pred = regressor.predict(X_validation_scaled)
regressor.score(X_validation_scaled, y_validation)

np.mean(y_test), np.std(y_test)

np.mean(y_pred), np.std(y_pred)

sns.histplot(y_pred, color='red')

sns.histplot(y_test, color='yellow')

regressor.predict([np.array(X_test)[0]])

from sklearn.metrics import mean_squared_error

y_pred_train = regressor.predict(X_train_scaled)
training_loss = mean_squared_error(y_pred_train, y_train)

y_test

y_train

sns.scatterplot(x=range(1, y_pred_train.shape[0]+1), y=y_train.iloc[:, 0], color='yellow')
sns.scatterplot(x=range(1, y_pred_train.shape[0]+1), y=y_pred_train[:, 0], color='red')
plt.show()

y_pred_train.shape

print(training_loss)

print(np.sqrt(training_loss))

pred = np.array([29916.162, 21108.912, 14879.802])
truth = np.array([26279.21225, 16584.64730,11846.808510])

print(np.sqrt((pred-truth)**2))

