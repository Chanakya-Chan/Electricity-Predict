# -*- coding: utf-8 -*-
"""Electricity Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PcLpkiVe1-AYKHInUSeL7S-tzXgI4apI
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

import tensorflow as tf
from tensorflow.keras.layers import Input, Dense
from tensorflow.keras.models import Sequential
from tensorflow.keras.metrics import RootMeanSquaredError

from sklearn.preprocessing import MinMaxScaler, StandardScaler
from sklearn.model_selection import train_test_split

import pickle
import io

seed = 42
tf.random.set_seed(seed)

# Install dependencies as needed:
# pip install kagglehub[pandas-datasets]
import kagglehub
from kagglehub import KaggleDatasetAdapter

# Set the path to the file you'd like to load
file_path = "powerconsumption.csv"

# Load the latest version
data_set = kagglehub.load_dataset(
  KaggleDatasetAdapter.PANDAS,
  "fedesoriano/electric-power-consumption",
  file_path,
  # Provide any additional arguments like
  # sql_query or pandas_kwargs. See the
  # documenation for more information:
  # https://github.com/Kaggle/kagglehub/blob/main/README.md#kaggledatasetadapterpandas
)

print("First 5 records:", data_set.head())

data_set['Datetime'] = pd.to_datetime(data_set['Datetime'], infer_datetime_format=True)

data_set['Day'] = data_set['Datetime'].dt.day
data_set['Month'] = data_set['Datetime'].dt.month
data_set['Year'] = data_set['Datetime'].dt.year

features = data_set.columns.to_list()
targets = [
    'PowerConsumption_Zone1',
    'PowerConsumption_Zone2',
    'PowerConsumption_Zone3'
    ]

for i in targets:
  features.remove(i)
features.remove('Datetime')

targets = ['PowerConsumption_Zone1']

X = data_set[features]
y = data_set[targets]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

scaler = StandardScaler()

X_train_transformed = scaler.fit_transform(X_train)

X_test_transformed = scaler.transform(X_test)

model = Sequential()

model.add(Dense(units=128, input_dim=X_train.shape[1], activation='relu'))
model.add(Dense(units=64, activation='relu'))
model.add(Dense(units=32, activation='relu'))
model.add(Dense(units=1, activation='linear'))

model.compile(optimizer='Adam', loss='mse', metrics=[RootMeanSquaredError()])
history = model.fit(X_train_transformed, y_train, epochs=100, validation_split=0.2)

y_pred = model.predict(X_test_transformed)
r2_score(y_test, y_pred)

from sklearn.metrics import r2_score

history.history.keys()

sns.lineplot(x=range(1, 101), y=history.history['root_mean_squared_error'], color='red')
sns.lineplot(x=range(1, 101), y=history.history['val_root_mean_squared_error'], color='yellow')

sns.lineplot(x=range(2, 101), y=history.history['root_mean_squared_error'][1:], color='red')
sns.lineplot(x=range(2, 101), y=history.history['val_root_mean_squared_error'][1:], color='yellow')





model_2 = Sequential()


model_2.add(Dense(units=32, input_dim=X_train.shape[1], activation='relu'))
model_2.add(Dense(units=64, activation='relu'))
model_2.add(Dense(units=128, activation='relu'))
model_2.add(Dense(units=256, activation='relu'))
model_2.add(Dense(units=1, activation='relu'))

model_2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.005),
                loss='mse',
                metrics=[RootMeanSquaredError()])

history_new = model_2.fit(x=X_train_transformed,
            y=y_train,
            epochs=200,
            validation_split=0.2)

sns.lineplot(x=range(1, 201), y=history_new.history['root_mean_squared_error'], color='red')
sns.lineplot(x=range(1, 201), y=history_new.history['val_root_mean_squared_error'], color='blue')

y_pred_new = model_2.predict(X_test_transformed)
r2_score(y_test, y_pred_new)

y_test





model_3 = Sequential()


model_3.add(Dense(units=32, input_dim=X_train.shape[1], activation='relu'))
model_3.add(Dense(units=64, activation='relu'))
model_3.add(Dense(units=128, activation='relu'))
model_3.add(Dense(units=256, activation='relu'))
model_3.add(Dense(units=1, activation='linear'))

model_3.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.005),
                loss='mse',
                metrics=[RootMeanSquaredError()])
history_m3 = model_3.fit(X_train_transformed,
            y_train,
            epochs=200,
            validation_split=0.2)

y_pred_m3 = model_3.predict(X_test_transformed)
r2_score(y_test, y_pred_m3)

sns.lineplot(x=range(2, 201), y=history_m3.history['root_mean_squared_error'][1:], color='red')
sns.lineplot(x=range(2, 201), y=history_m3.history['val_root_mean_squared_error'][1:], color='yellow')











from tensorflow.keras.layers import Dropout

# model_3 + 512 neurons layer + dropout(0.5)

model_do = Sequential()


model_do.add(Dense(units=32, input_dim=X_train.shape[1], activation='relu'))
model_do.add(Dense(units=64, activation='relu'))
model_do.add(Dense(units=128, activation='relu'))
model_do.add(Dense(units=256, activation='relu'))
model_do.add(Dense(units=512, activation='relu'))
model_do.add(Dropout(0.5))
model_do.add(Dense(units=1, activation='linear'))

model_do.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.005),
                 loss='mse',
                 metrics=[RootMeanSquaredError()])
history_do = model_do.fit(x=X_train_transformed,
             y=y_train,
             epochs=100,
             validation_split=0.2)

y_pred_do = model_do.predict(X_test_transformed)
r2_score(y_test, y_pred_do)

sns.lineplot(x=range(2, 101), y=history_do.history['root_mean_squared_error'][1:], color='red')
sns.lineplot(x=range(2, 101), y=history_do.history['val_root_mean_squared_error'][1:], color='blue')





# model_3 + dropout(0.3)

model_do_2 = Sequential()


model_do_2.add(Dense(units=32, input_dim=X_train.shape[1], activation='relu'))
model_do_2.add(Dense(units=64, activation='relu'))
model_do_2.add(Dense(units=128, activation='relu'))
model_do_2.add(Dense(units=256, activation='relu'))
model_do_2.add(Dropout(0.3))
model_do_2.add(Dense(units=1, activation='linear'))

model_do_2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.005),
                   loss='mse',
                   metrics=[RootMeanSquaredError()])
history_do_m2 = model_do_2.fit(x=X_train_transformed,
                               y=y_train,
                               epochs=200,
                               validation_split=0.2)

y_pred_do_m2 = model_do_2.predict(X_test_transformed)
r2_score(y_test, y_pred_do_m2)

sns.lineplot(x=range(2, 201), y=history_do_m2.history['root_mean_squared_error'][1:], color='red')
sns.lineplot(x=range(2, 201), y=history_do_m2.history['val_root_mean_squared_error'][1:], color='yellow')











sns.lineplot(x=range(2, 101), y=history.history['root_mean_squared_error'][1:], color='red', label="model")
sns.lineplot(x=range(2, 201), y=history_new.history['root_mean_squared_error'][1:], color='blue', label="model_2")
sns.lineplot(x=range(2, 201), y=history_m3.history['root_mean_squared_error'][1:], color='green', label="model_3")
sns.lineplot(x=range(2, 101), y=history_do.history['root_mean_squared_error'][1:], color='yellow', label="model_do")
sns.lineplot(x=range(2, 201), y=history_do_m2.history['root_mean_squared_error'][1:], color='orange', label="model_do_m2")



from sklearn.metrics import root_mean_squared_error

mean_val = np.mean(y_test)

comparisions = {
    "model": {
        "Relative RMSE": root_mean_squared_error(y_test, y_pred)/mean_val,
        "R2 score": r2_score(y_test, y_pred)
    },

    "model_2": {
        "Relative RMSE": root_mean_squared_error(y_test, y_pred_new)/mean_val,
        "R2 score": r2_score(y_test, y_pred_new)
    },

    "model_3": {
        "Relative RMSE": root_mean_squared_error(y_test, y_pred_m3)/mean_val,
        "R2 score": r2_score(y_test, y_pred_m3),
    },

    "model_do": {
        "Relative RMSE": root_mean_squared_error(y_test, y_pred_do)/mean_val,
        "R2 score": r2_score(y_test, y_pred_do)
    },

    "model_do_2": {
        "Relative RMSE": root_mean_squared_error(y_test, y_pred_do_m2)/mean_val,
        "R2 score": r2_score(y_test, y_pred_do_m2)
    }
}

pd.DataFrame(comparisions)

with open('best model.pkl', 'wb') as f:
  pickle.dump(model_3, f)

with open('model 1.pkl', 'wb') as f:
  pickle.dump(model, f)
  f.close()

with open('model 2.pkl', 'wb') as f:
  pickle.dump(model_2, f)
  f.close()

with open('model DO.pkl', 'wb') as f:
  pickle.dump(model_do, f)
  f.close()

with open('model DO 2.pkl', 'wb') as f:
  pickle.dump(model_do_2, f)
  f.close()

